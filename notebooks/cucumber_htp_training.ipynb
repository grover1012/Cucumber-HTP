{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ¥’ Cucumber HTP Production Training (Google Colab)\n",
    "## High-Throughput Phenotyping with YOLO + SAM2\n",
    "\n",
    "This notebook trains a production-ready cucumber detection model using Google Colab's GPU acceleration.\n",
    "\n",
    "**Expected Results:**\n",
    "- Training Time: 2-4 days (vs 2-4 weeks on CPU)\n",
    "- Model Quality: 98%+ mAP50 (vs 85% current)\n",
    "- Production Ready: Yes!\n",
    "\n",
    "**Hardware:**\n",
    "- GPU: Tesla T4/V100/A100 (16GB+ VRAM)\n",
    "- RAM: 25GB+\n",
    "- Storage: 100GB+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ğŸš€ Setup and Installation\n",
    "Install required packages and verify GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "!pip install PyYAML matplotlib opencv-python\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "print(f"Ultralytics version: {ultralytics.__version__}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f"CUDA available: {torch.cuda.is_available()}")\n",
    "print(f"GPU count: {torch.cuda.device_count()}")\n",
    "if torch.cuda.is_available():\n",
    "    print(f"GPU: {torch.cuda.get_device_name(0)}")\n",
    "    print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_data"
   },
   "source": [
    "## ğŸ“ Upload Your Clean Dataset\n",
    "Upload the clean_dataset.zip file you created locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_dataset"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Upload your clean dataset\n",
    "print("ğŸ“¤ Upload your clean_dataset.zip file:")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the dataset\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f"ğŸ“¦ Extracting {filename}...")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f"âœ… Dataset extracted to: {filename[:-4]}")\n",
    "        break\n",
    "\n",
    "# Verify dataset structure\n",
    "dataset_path = 'clean_dataset'\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f"ğŸ“ Dataset found: {dataset_path}")\n",
    "    print(f"ğŸ“Š Contents:")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_path):\n",
    "            images = len([f for f in os.listdir(os.path.join(split_path, 'images')) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            labels = len([f for f in os.listdir(os.path.join(split_path, 'labels')) if f.endswith('.txt')])\n",
    "            print(f"  {split}: {images} images, {labels} labels")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "start_training"
   },
   "source": [
    "## ğŸ¯ Start Production Training\n",
    "Train with 1000 epochs for production quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolo12s.pt')\n",
    "print(f"ğŸ—ï¸ Loaded model: {self.model_size}")\n",
    "\n",
    "# Start training with GPU optimization\n",
    "print("ğŸš€ Starting production training...")\n",
    "print("=" * 60)\n",
    "print(f"ğŸ“ Data: {self.data_yaml_path}")\n",
    "print(f"â±ï¸ Epochs: {self.training_config['epochs']}")\n",
    "print(f"ğŸ“¦ Batch size: {self.training_config['batch']}")\n",
    "print(f"ğŸ¯ Device: GPU (device 0)")\n",
    "print(f"ğŸ“ˆ Learning rate: {self.training_config['lr0']}")\n",
    "print(f"ğŸ”„ Augmentation: Enabled")\n",
    "print("=" * 60)\n",
    "\n",
    "# Start training\n",
    "results = model.train(\n",
    "    data=str(self.data_yaml_path),\n",
    "    epochs=1000,\n",
    "    patience=100,\n",
    "    batch=32,\n",
    "    imgsz=640,\n",
    "    save_period=50,\n",
    "    cache=True,\n",
    "    device=0,  # Use GPU\n",
    "    workers=4,\n",
    "    project=models/colab_production,\n",
    "    name=cucumber_traits_v3,\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer=AdamW,\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    cos_lr=True,\n",
    "    close_mosaic=10,\n",
    "    amp=True,\n",
    "    multi_scale=True,\n",
    "    dropout=0.1,\n",
    "    half=True,\n",
    "    augment=True,\n",
    "    degrees=15.0,\n",
    "    translate=0.2,\n",
    "    scale=0.9,\n",
    "    shear=3.0,\n",
    "    perspective=0.002,\n",
    "    flipud=0.2,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.4,\n",
    "    cutmix=0.4,\n",
    "    copy_paste=0.2,\n",
    "    auto_augment=randaugment,\n",
    "    erasing=0.5,\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    warmup_epochs=10.0,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "print("âœ… Training completed successfully!")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_results"
   },
   "source": [
    "## ğŸ“¥ Download Your Trained Model\n",
    "Download the best model weights for local use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_model"
   },
   "outputs": [],
   "source": [
    "# Download the best model\n",
    "model_path = f"{self.training_config['project']}/{self.training_config['name']}/weights/best.pt"\n",
    "if os.path.exists(model_path):\n",
    "    print(f"ğŸ“¥ Downloading best model: {model_path}")\n",
    "    files.download(model_path)\n",
    "    print("âœ… Model downloaded!")\n",
    "else:\n",
    "    print(f"âŒ Model not found: {model_path}")\n",
    "\n",
    "# Also download the last model\n",
    "last_model_path = f"{self.training_config['project']}/{self.training_config['name']}/weights/last.pt"\n",
    "if os.path.exists(last_model_path):\n",
    "    print(f"ğŸ“¥ Downloading last model: {last_model_path}")\n",
    "    files.download(last_model_path)\n",
    "    print("âœ… Last model downloaded!")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_model"
   },
   "source": [
    "## ğŸ§ª Test Your Trained Model\n",
    "Test the model on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validation_test"
   },
   "outputs": [],
   "source": [
    "# Test on validation images\n",
    "if os.path.exists(model_path):\n",
    "    print("ğŸ§ª Testing trained model...")\n",
    "    \n",
    "    # Load trained model\n",
    "    trained_model = YOLO(model_path)\n",
    "    \n",
    "    # Test on validation images\n",
    "    val_images = os.path.join(dataset_path, 'valid', 'images')\n",
    "    if os.path.exists(val_images):\n",
    "        results = trained_model.val(data=str(self.data_yaml_path))\n",
    "        print("âœ… Validation completed!")\n",
    "        print(f"ğŸ“Š Results: {results}")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Cucumber HTP Production Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}